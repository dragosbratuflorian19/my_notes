{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Date, time built-in functions\n",
    "-DATE: YYYYMMDD <br>\n",
    "-TIME: HHMMSS <br>\n",
    "-TIMESTAMP: YYYYXXDDHHMMSSZZZZZ <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SELECT DAY(saledate)<br>\n",
    "FROM petsale<br>\n",
    "WHERE animal='cat';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SELECT COUNT(* ) from petsale<br>\n",
    "WHERE MONTH(saledate)='05';"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SELECT (saledate + 3 DAYS)<br>\n",
    "FROM petsale;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SELECT (CURRENT_DATE - saledate) <br>\n",
    "FROM petsale;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sub-Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SELECT *<br>\n",
    "FROM table1<br>\n",
    "WHERE salary < <br>\n",
    "(  SELECT AVG(salary)<br>\n",
    "   FROM table1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column expressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SELECT emp_id, salary,<br>\n",
    "(SELECT AVG(salary) FROM employees) as avg_salary<br>\n",
    "FROM employees;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Joins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SELECT * FROM employees, departments<br>\n",
    "WHERE employees.dep_id = departments.dept_id_dep;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inner join: intersection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Left outer join: right table side will have none values <br>\n",
    "Right outer join: Left table side will have none values <br>\n",
    "Full outer join: Both tables sides will gave none values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### dbmodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dbmodule import connect\n",
    "\n",
    "# Create the connection\n",
    "connection = connect('databasename', 'username', 'password')\n",
    "\n",
    "# Create cursor\n",
    "cursor = connection.cursor()\n",
    "\n",
    "# Run queries\n",
    "cursor.execute('SELECT * FROM mytable')\n",
    "Results = cursor.fetchall()\n",
    "\n",
    "# Free resources\n",
    "cursor.close()\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ibm_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ibm_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ibm_db\n",
    "\n",
    "# First, get credentials from IBM: Db2 -> Service Credentials -> New Credentials ->\n",
    "dsn_hostname = \"dashdb-txn-sbox-yp-lon02-04.services.eu-gb.bluemix.net\"\n",
    "dsn_uid = \"rdj81688\"\n",
    "dsn_pwd = \"289xd1lw-zfjsj09\"\n",
    "dsn_driver = \"{IBM DB2 ODBC DRIVER}\"\n",
    "dsn_database = \"BLUDB\"\n",
    "dsn_port = \"50000\"\n",
    "dsn_protocol = \"TCPIP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create database string\n",
    "dsn = f\"\"\"\n",
    "    DRIVER={dsn_driver};\n",
    "    DATABASE={dsn_database};\n",
    "    HOSTNAME={dsn_hostname};\n",
    "    PORT={dsn_port};\n",
    "    PROTOCOL={dsn_protocol};\n",
    "    UID={dsn_uid};\n",
    "    PWD={dsn_pwd};\n",
    "    \"\"\"\n",
    "\n",
    "print(dsn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create database connection\n",
    "try:\n",
    "    conn = ibm_db.connect(dsn, \"\", \"\")\n",
    "    print (\"Connected to database: \", dsn_database, \"as user: \", dsn_uid, \"on host: \", dsn_hostname)\n",
    "\n",
    "except:\n",
    "    print (\"Unable to connect: \", ibm_db.conn_errormsg() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve metadata from server\n",
    "server = ibm_db.server_info(conn)\n",
    "\n",
    "print (\"DBMS_NAME: \", server.DBMS_NAME)\n",
    "print (\"DBMS_VER:  \", server.DBMS_VER)\n",
    "print (\"DB_NAME:   \", server.DB_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve metadata from database client\n",
    "client = ibm_db.client_info(conn)\n",
    "\n",
    "print (\"DRIVER_NAME:          \", client.DRIVER_NAME) \n",
    "print (\"DRIVER_VER:           \", client.DRIVER_VER)\n",
    "print (\"DATA_SOURCE_NAME:     \", client.DATA_SOURCE_NAME)\n",
    "print (\"DRIVER_ODBC_VER:      \", client.DRIVER_ODBC_VER)\n",
    "print (\"ODBC_VER:             \", client.ODBC_VER)\n",
    "print (\"ODBC_SQL_CONFORMANCE: \", client.ODBC_SQL_CONFORMANCE)\n",
    "print (\"APPL_CODEPAGE:        \", client.APPL_CODEPAGE)\n",
    "print (\"CONN_CODEPAGE:        \", client.CONN_CODEPAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stmt = ibm_db.exec_immediate(conn, \n",
    "\"\"\"\n",
    "SELECT * FROM EMPLOYEES\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibm_db.fetch_both(stmt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ibm_db.close(conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pandas ibm_db_dbi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ibm_db_dbi\n",
    "pconn = ibm_db_dbi.Connection(conn)\n",
    "df = pandas.read_sql('SELECT * FROM table', pconn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accessing Db2 database with magic method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ipython-sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install ibm_db_sa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql ibm_db_sa://rdj81688:289xd1lw-zfjsj09@dashdb-txn-sbox-yp-lon02-04.services.eu-gb.bluemix.net:50000/BLUDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sql\n",
    "\n",
    "CREATE TABLE INTERNATIONAL_STUDENT_TEST_SCORES (\n",
    "\tcountry VARCHAR(50),\n",
    "\tfirst_name VARCHAR(50),\n",
    "\tlast_name VARCHAR(50),\n",
    "\ttest_score INT\n",
    ");\n",
    "INSERT INTO INTERNATIONAL_STUDENT_TEST_SCORES (country, first_name, last_name, test_score)\n",
    "VALUES\n",
    "('United States', 'Marshall', 'Bernadot', 54),\n",
    "('Australia', 'Eduard', 'Leipelt', 53)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country = 'Canada'\n",
    "%sql select * from table where country = :country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = %sql SELECT testscore as \"Test Score\", count(*) from table ;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pandas, ibm_db and matplotlib some magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ibm_db_sa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql ibm_db_sa://rdj81688:289xd1lw-zfjsj09@dashdb-txn-sbox-yp-lon02-04.services.eu-gb.bluemix.net:50000/BLUDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking the number of records\n",
    "%sql SELECT COUNT(*) FROM table;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Executing cmd commands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install --upgrade pip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# R Studio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Uploading a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = read.csv('./Documents/my_notes/my_notes/ML/data/my_data.csv', header = False)\n",
    "View(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### R Packages\n",
    "cran.r-project.org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Installing packages\n",
    "install.packages('audio')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load a package\n",
    "library(audio) <br>\n",
    "play(sin(1:10000/20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = rnorm(100)\n",
    "y = rnorm(100, sd = 10)\n",
    "\n",
    "df = data.frame(x, y)\n",
    "view(df)\n",
    "\n",
    "library(ggplot2)\n",
    "ggplot(df, aes(x = weight, y = height)) + geom_point()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Jupyter notebooks in watson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can create jobs, import other code from other jupyter notebooks etc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis with Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import a .csv file without a header\n",
    "import pandas as pd\n",
    "url = 'https://...'\n",
    "df = pd.read_csv(url, header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace headers\n",
    "headers = ['Col1', 'Col2', 'Col3']\n",
    "df.columns = headers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas also read:\n",
    "- json files\n",
    "- excel files\n",
    "- sql files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe() # works for numerical columns\n",
    "df.describe(include='all') # for all columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Handle missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Doesn't change the dataframe\n",
    "df.dropna(subset=['col1'], axis=0)\n",
    "# Changes the dataframe\n",
    "df.dropna(subset=['col1'], axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the missing values\n",
    "mean_val = df['target_column'].mean()\n",
    "df.replace(np.nan, mean_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple scale\n",
    "df['target'] = df['target']/df['target'].max()\n",
    "# Min-Max\n",
    "df['target'] = (df['target'] - df['target'].min())/(df['target'].max() - df['target'].min())\n",
    "# Z score\n",
    "df['target'] = (df['target'] - df['target'].mean())/df['target'].std() # Bewtween ( -3 +3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binning - grouping values into bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.linspace(min(df['price']), max(df['price']), 4)\n",
    "group_names = ['Low','Medium','High']\n",
    "df['priced_bins'] = pd.cut(df['price'], bins, labels = group_names, include_lowest=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming categorical data into 1 and 0\n",
    "pd.get_dummies(df['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Descriptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.describe()\n",
    "# Box plots: good to observe outliers\n",
    "sns.boxplot(x='engine', y='price', data=df)\n",
    "# Scatterplots\n",
    "x = df['price]\n",
    "y = df['engine']\n",
    "plt.scatter(x, y)\n",
    "plt.title('Title')\n",
    "plt.xlabel('X Axis')\n",
    "plt.ylabel('Y Axis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grouping by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df[['col1','col2','col3']]\n",
    "grouped_df = new_df.groupby(['col1', 'col2'], as_index=False).mean()\n",
    "df.pivot(index='col1', columns=['col2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Corelation(pearson coefficient) and p-value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation coefficient: <br>\n",
    "- +1 large positive relashionship\n",
    "- -1 large negative relashionship\n",
    "- 0  no relashionship <br>\n",
    "\n",
    "P-value: <br>\n",
    "- p-value < 0.001 Strong certainty in the result\n",
    "- p-value < 0.05 Moderate certainty in the result\n",
    "- p-value < 0.1 Weak certainty in the result\n",
    "- p-value > 0.1 No certainty in the result\n",
    "\n",
    "e.g of strong correlation: cc = 1/-1 and p-value < 0.001<br>\n",
    "Correlation heatmap shows all the correlations, with 1 on 2nd diagonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_coef, p_value = stats.pearsonr(df['col1'], df['col2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find a correlation and ilustrate it\n",
    "df[['col1', 'col2']].corr()\n",
    "sns.regplot(x='col1', y='col2', data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ANOVA - Analysis of Variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. F score : difference between mediums. Difference between mediums is then compared with the variance of a class\n",
    "2. p-value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "df_anova = df[['brand', 'price']]\n",
    "grouped_anova = df_anova.groupby(['make'])\n",
    "anova_results = stats.f_oneway(grouped_anova.get_group('honda')['price'], grouped_anova.get_group('subaru')['price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To count categorical values\n",
    "df['col1'].value_counts().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new column with the value counts\n",
    "df_counts = df['target'].value_counts().to_frame()\n",
    "df_counts.rename(columns={'col1':'col2'}, inplace=True)\n",
    "df_counts.index.name='index_name'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different types of regression:\n",
    "- Simple linear regression (SLR)\n",
    "- Multiple linear regression (MLR)\n",
    "- Polynomial regression (PR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SLR\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "slr = LinearRegression()\n",
    "X = ...\n",
    "y = ...\n",
    "slr.fit(X, y)\n",
    "y_hat = slr.predict(z)\n",
    "slr.intercept_ # b0/intercept\n",
    "slr.coef_ # b1/slope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLR\n",
    "X = df[['var1', 'var2', 'var3', 'var4']]\n",
    "mlr.fit(Z, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PR\n",
    "\n",
    "# Visualization function\n",
    "def PlotPolly(model, independent_variable, dependent_variabble, Name):\n",
    "    x_new = np.linspace(15, 55, 100)\n",
    "    y_new = model(x_new)\n",
    "\n",
    "    plt.plot(independent_variable, dependent_variabble, '.', x_new, y_new, '-')\n",
    "    plt.title('Polynomial Fit with Matplotlib for Price ~ Length')\n",
    "    ax = plt.gca()\n",
    "    ax.set_facecolor((0.898, 0.898, 0.898))\n",
    "    fig = plt.gcf()\n",
    "    plt.xlabel(Name)\n",
    "    plt.ylabel('Price of Cars')\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "# Values\n",
    "x = df['highway-mpg']\n",
    "y = df['price']\n",
    "\n",
    "# Here we use a polynomial of the 3rd order (cubic) \n",
    "f = np.polyfit(x, y, 3)\n",
    "p = np.poly1d(f)\n",
    "print(p)\n",
    "\n",
    "# Plotting\n",
    "PlotPolly(p, x, y, 'highway-mpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a rezidual plot ( to see how the error is, if a curved line is needed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.regplot(x = 'x-axis', y='y-axis', data = df)\n",
    "sns.residplot(df['x-axis'], df['y-axis'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating a distribution plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax1 = sns.displot(df['price'], hist=False, color='r', label='Actual Value')\n",
    "sns.displot(Yhat, hist=False, color=\"b\", label=\"Fitted Values\", ax=ax1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pipelines\n",
    "data -> Normalization -> Polynomial Transformation -> Linear Regression -> prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ways to determine the efficiency of a model:\n",
    "1. MSE: mean squared error:<br>\n",
    "from sklearn import mean_squared_error <br>\n",
    "mean_squared_error(actual, predicted)<br>\n",
    "2. Rˆ2: R squared:<br>\n",
    "slr.score(actual, predicted)<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Doing Cross validation (4 folds, each fold will be test subset)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(slr, x_data, y_data, cv=3) # dataset split into 3 different partitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ridge regression ( when using higher lvl polinomial regression, to deny outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "ridge_model = Ridge(alpha=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid search (used to choose the parameters for the model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "parameters = [{'alpha':[0.001, 0.01, 1, 10, 1000], 'normalize':[True, False]}]\n",
    "ridge_model = Ridge()\n",
    "Grid1 = GridSearchCV(ridge_model, parameters, cv=4)\n",
    "Grid1.fit(X, y)\n",
    "Grid1.best_estimator_\n",
    "scores = Grid1.cv_results_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# %matplotlib notebook - interactive\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(5, 5, 'o')\n",
    "plt.title('Plotting Example')\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Direct plot function in pandas module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading data from an excel\n",
    "# !pip install xlrd\n",
    "# df = pd.read_excel('https://...', sheet_name='dsad', skiprows=range(10), skipfooter=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_can = pd.read_csv('canada.csv')\n",
    "df_can.drop(columns=[' ' ,'Type', 'Coverage', 'AREA', 'REG', 'RegName', 'DEV', 'DevName'], axis=0, inplace=True)\n",
    "df_can.rename(columns={'OdName':'Country', 'AreaName': 'Continent'}, inplace=True)\n",
    "df_can = df_can.set_index('Country')\n",
    "# df_can = df_can.T\n",
    "# df_can = df_can[['China', 'India']]\n",
    "df_can['Total'] = df_can.sum(axis=1)\n",
    "df_can.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_can.plot(kind='line')\n",
    "df_can.loc['Haiti', list(map(str, range(1980, 2014)))].plot(kind='line')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_can['India'].plot(kind='hist')\n",
    "df_can.loc['Haiti', list(map(str, range(1980, 2014)))].plot(kind='hist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "count, bin_edges = np.histogram(df_can['2013'])\n",
    "\n",
    "df_can['2013'].plot(kind='hist', figsize=(8, 5), xticks=bin_edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_t = df_can.loc[['Denmark', 'Norway', 'Sweden'], list(map(str, range(1980, 2014)))].transpose()\n",
    "\n",
    "count, bin_edges = np.histogram(df_t, 15)\n",
    "xmin = bin_edges[0] - 10   #  first bin value is 31.0, adding buffer of 10 for aesthetic purposes \n",
    "xmax = bin_edges[-1] + 10  #  last bin value is 308.0, adding buffer of 10 for aesthetic purposes\n",
    "\n",
    "# stacked Histogram\n",
    "df_t.plot(kind='hist',\n",
    "          figsize=(10, 6), \n",
    "          bins=15,\n",
    "          xticks=bin_edges,\n",
    "          color=['coral', 'darkslateblue', 'mediumseagreen'],\n",
    "          stacked=True,\n",
    "          xlim=(xmin, xmax)\n",
    "         )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Area plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_can.sort_values(['Total'], ascending = False, axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top = df_can.head()\n",
    "df_top = df_top[list(map(str, range(1980, 2014)))].transpose()\n",
    "df_top.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top.plot(kind='area',figsize=(20, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_top.index = df_top.index.map(int) # let's change the index values of df_top5 to type integer for plotting\n",
    "df_top.plot(kind='area', \n",
    "             alpha=0.25, # 0-1, default value a= 0.5\n",
    "             stacked=False,\n",
    "             figsize=(20, 10),\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Barchart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iceland = df_can.loc['Iceland', list(map(str, range(1980, 2014)))]\n",
    "df_iceland.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_iceland.plot(kind='bar', figsize=(10, 6), rot=90) \n",
    "\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Immigrants')\n",
    "plt.title('Icelandic Immigrants to Canada from 1980 to 2013')\n",
    "\n",
    "# Annotate arrow\n",
    "plt.annotate('',                      # s: str. will leave it blank for no text\n",
    "             xy=(32, 70),             # place head of the arrow at point (year 2012 , pop 70)\n",
    "             xytext=(28, 20),         # place base of the arrow at point (year 2008 , pop 20)\n",
    "             xycoords='data',         # will use the coordinate system of the object being annotated \n",
    "             arrowprops=dict(arrowstyle='->', connectionstyle='arc3', color='blue', lw=2)\n",
    "            )\n",
    "\n",
    "# Annotate Text\n",
    "plt.annotate('2008 - 2011 Financial Crisis', # text to display\n",
    "             xy=(28, 30),                    # start the text at at point (year 2008 , pop 30)\n",
    "             rotation=72.5,                  # based on trial and error to match the arrow\n",
    "             va='bottom',                    # want the text to be vertically 'bottom' aligned\n",
    "             ha='left',                      # want the text to be horizontally 'left' algned.\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pie charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cont = df_can.groupby('Continent', axis=0).sum()\n",
    "df_cont"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cont['Total'].plot(kind='pie')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_list = ['gold', 'yellowgreen', 'lightcoral', 'lightskyblue', 'lightgreen', 'pink']\n",
    "explode_list = [0.1, 0, 0, 0, 0.1, 0.1] # ratio for each continent with which to offset each wedge.\n",
    "\n",
    "df_cont['Total'].plot(kind='pie',\n",
    "                            figsize=(15, 6),\n",
    "                            autopct='%1.1f%%', \n",
    "                            startangle=90,    \n",
    "                            shadow=True,       \n",
    "                            labels=None,         # turn off labels on pie chart\n",
    "                            pctdistance=1.12,    # the ratio between the center of each pie slice and the start of the text generated by autopct \n",
    "                            colors=colors_list,  # add custom colors\n",
    "                            explode=explode_list # 'explode' lowest 3 continents\n",
    "                            )\n",
    "\n",
    "# scale the title up by 12% to match pctdistance\n",
    "plt.title('Immigration to Canada by Continent [1980 - 2013]', y=1.12) \n",
    "\n",
    "plt.axis('equal') \n",
    "\n",
    "# add legend\n",
    "plt.legend(labels=df_cont.index, loc='upper left') \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Box plots\n",
    "Useful to detect outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df_japan = df_can.loc[['Japan'], list(map(str, range(1980, 2014)))].transpose()\n",
    "df_japan.plot(kind='box', figsize=(10, 7), color='blue', vert=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sub plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure() # create figure\n",
    "\n",
    "ax0 = fig.add_subplot(1, 2, 1) # add subplot 1 (1 row, 2 columns, first plot)\n",
    "ax1 = fig.add_subplot(1, 2, 2) # add subplot 2 (1 row, 2 columns, second plot). See tip below**\n",
    "\n",
    "# Subplot 1: Box plot\n",
    "df_japan.plot(kind='box', color='blue', vert=False, figsize=(20, 6), ax=ax0) # add to subplot 1\n",
    "ax0.set_title('Box Plots of Immigrants from China and India (1980 - 2013)')\n",
    "ax0.set_xlabel('Number of Immigrants')\n",
    "ax0.set_ylabel('Countries')\n",
    "\n",
    "# Subplot 2: Line plot\n",
    "df_japan.plot(kind='line', figsize=(20, 6), ax=ax1) # add to subplot 2\n",
    "ax1.set_title ('Line Plots of Immigrants from China and India (1980 - 2013)')\n",
    "ax1.set_ylabel('Number of Immigrants')\n",
    "ax1.set_xlabel('Years')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tot = pd.DataFrame(df_can[list(map(str, range(1980, 2014)))].sum(axis=0))\n",
    "df_tot.index = map(int, df_tot.index)\n",
    "df_tot.reset_index(inplace = True)\n",
    "df_tot.columns = ['year', 'total']\n",
    "df_tot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tot.plot(kind='scatter', x='year', y='total', figsize=(10, 6), color='darkblue')\n",
    "\n",
    "plt.title('Total Immigration to Canada from 1980 - 2013')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Immigrants')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df_tot['year']      # year on x-axis\n",
    "y = df_tot['total']     # total on y-axis\n",
    "fit = np.polyfit(x, y, deg=1)\n",
    "\n",
    "fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tot.plot(kind='scatter', x='year', y='total', figsize=(10, 6), color='darkblue')\n",
    "\n",
    "plt.title('Total Immigration to Canada from 1980 - 2013')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Immigrants')\n",
    "\n",
    "# plot line of best fit\n",
    "plt.plot(x, fit[0] * x + fit[1], color='red') # recall that x is the Years\n",
    "plt.annotate('y={0:.0f} x + {1:.0f}'.format(fit[0], fit[1]), xy=(2000, 150000))\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# print out the line of best fit\n",
    "'No. Immigrants = {0:.0f} * Year + {1:.0f}'.format(fit[0], fit[1]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Bubble plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_can_t = df_can[list(map(str, range(1980, 2014)))].transpose() # transposed dataframe\n",
    "\n",
    "# cast the Years (the index) to type int\n",
    "df_can_t.index = map(int, df_can_t.index)\n",
    "\n",
    "# let's label the index. This will automatically be the column name when we reset the index\n",
    "df_can_t.index.name = 'Year'\n",
    "\n",
    "# reset index to bring the Year in as a column\n",
    "df_can_t.reset_index(inplace=True)\n",
    "\n",
    "# view the changes\n",
    "df_can_t.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize Brazil data\n",
    "norm_brazil = (df_can_t['Brazil'] - df_can_t['Brazil'].min()) / (df_can_t['Brazil'].max() - df_can_t['Brazil'].min())\n",
    "\n",
    "# normalize Argentina data\n",
    "norm_argentina = (df_can_t['Argentina'] - df_can_t['Argentina'].min()) / (df_can_t['Argentina'].max() - df_can_t['Argentina'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Brazil\n",
    "ax0 = df_can_t.plot(kind='scatter',\n",
    "                    x='Year',\n",
    "                    y='Brazil',\n",
    "                    figsize=(14, 8),\n",
    "                    alpha=0.5,                  # transparency\n",
    "                    color='red',\n",
    "                    s=norm_brazil * 2000 + 10,  # pass in weights \n",
    "                    xlim=(1975, 2015)\n",
    "                   )\n",
    "\n",
    "# Argentina\n",
    "ax1 = df_can_t.plot(kind='scatter',\n",
    "                    x='Year',\n",
    "                    y='Argentina',\n",
    "                    alpha=0.5,\n",
    "                    color=\"yellow\",\n",
    "                    s=norm_argentina * 2000 + 10,\n",
    "                    ax = ax0\n",
    "                   )\n",
    "\n",
    "ax0.set_ylabel('Number of Immigrants')\n",
    "ax0.set_title('Immigration from Brazil and Argentina from 1980 - 2013')\n",
    "ax0.legend(['Brazil', 'Argentina'], loc='upper left', fontsize='x-large')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Waffle chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches # needed for waffle Charts\n",
    "\n",
    "mpl.style.use('ggplot') # optional: for ggplot-like style\n",
    "\n",
    "# check for latest version of Matplotlib\n",
    "print ('Matplotlib version: ', mpl.__version__) # >= 2.0.0\n",
    "\n",
    "df_dsn = df_can.loc[['Denmark', 'Norway', 'Sweden'], :]\n",
    "\n",
    "def create_waffle_chart(categories, values, height, width, colormap, value_sign=''):\n",
    "\n",
    "    # compute the proportion of each category with respect to the total\n",
    "    total_values = sum(values)\n",
    "    category_proportions = [(float(value) / total_values) for value in values]\n",
    "\n",
    "    # compute the total number of tiles\n",
    "    total_num_tiles = width * height # total number of tiles\n",
    "    print ('Total number of tiles is', total_num_tiles)\n",
    "    \n",
    "    # compute the number of tiles for each catagory\n",
    "    tiles_per_category = [round(proportion * total_num_tiles) for proportion in category_proportions]\n",
    "\n",
    "    # print out number of tiles per category\n",
    "    for i, tiles in enumerate(tiles_per_category):\n",
    "        print (df_dsn.index.values[i] + ': ' + str(tiles))\n",
    "    \n",
    "    # initialize the waffle chart as an empty matrix\n",
    "    waffle_chart = np.zeros((height, width))\n",
    "\n",
    "    # define indices to loop through waffle chart\n",
    "    category_index = 0\n",
    "    tile_index = 0\n",
    "\n",
    "    # populate the waffle chart\n",
    "    for col in range(width):\n",
    "        for row in range(height):\n",
    "            tile_index += 1\n",
    "\n",
    "            # if the number of tiles populated for the current category \n",
    "            # is equal to its corresponding allocated tiles...\n",
    "            if tile_index > sum(tiles_per_category[0:category_index]):\n",
    "                # ...proceed to the next category\n",
    "                category_index += 1       \n",
    "            \n",
    "            # set the class value to an integer, which increases with class\n",
    "            waffle_chart[row, col] = category_index\n",
    "    \n",
    "    # instantiate a new figure object\n",
    "    fig = plt.figure()\n",
    "\n",
    "    # use matshow to display the waffle chart\n",
    "    colormap = plt.cm.coolwarm\n",
    "    plt.matshow(waffle_chart, cmap=colormap)\n",
    "    plt.colorbar()\n",
    "\n",
    "    # get the axis\n",
    "    ax = plt.gca()\n",
    "\n",
    "    # set minor ticks\n",
    "    ax.set_xticks(np.arange(-.5, (width), 1), minor=True)\n",
    "    ax.set_yticks(np.arange(-.5, (height), 1), minor=True)\n",
    "    \n",
    "    # add dridlines based on minor ticks\n",
    "    ax.grid(which='minor', color='w', linestyle='-', linewidth=2)\n",
    "\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "    # compute cumulative sum of individual categories to match color schemes between chart and legend\n",
    "    values_cumsum = np.cumsum(values)\n",
    "    total_values = values_cumsum[len(values_cumsum) - 1]\n",
    "\n",
    "    # create legend\n",
    "    legend_handles = []\n",
    "    for i, category in enumerate(categories):\n",
    "        if value_sign == '%':\n",
    "            label_str = category + ' (' + str(values[i]) + value_sign + ')'\n",
    "        else:\n",
    "            label_str = category + ' (' + value_sign + str(values[i]) + ')'\n",
    "            \n",
    "        color_val = colormap(float(values_cumsum[i])/total_values)\n",
    "        legend_handles.append(mpatches.Patch(color=color_val, label=label_str))\n",
    "\n",
    "    # add legend to chart\n",
    "    plt.legend(\n",
    "        handles=legend_handles,\n",
    "        loc='lower center', \n",
    "        ncol=len(categories),\n",
    "        bbox_to_anchor=(0., -0.2, 0.95, .1)\n",
    "    )\n",
    "\n",
    "width = 40 # width of chart\n",
    "height = 10 # height of chart\n",
    "\n",
    "categories = df_dsn.index.values # categories\n",
    "values = df_dsn['Total'] # correponding values of categories\n",
    "\n",
    "colormap = plt.cm.coolwarm # color map class\n",
    "\n",
    "create_waffle_chart(categories, values, height, width, colormap)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = pd.read_csv('players_20.csv')\n",
    "pd.set_option('display.max_columns', 500)\n",
    "fp = fp[['short_name', 'age', 'height_cm', 'nationality', 'club', 'overall', 'value_eur', 'wage_eur', 'team_position', 'pace', 'dribbling']]\n",
    "fp.sort_values(['dribbling'], ascending = False, axis=0, inplace=False).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### World cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install wordcloud\n",
    "!conda install -c conda-forge wordcloud==1.4.1 --yes\n",
    "\n",
    "# import package and its set of stopwords\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "\n",
    "print ('Wordcloud is installed and imported!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download file and save as alice_novel.txt\n",
    "!wget --quiet https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DV0101EN/labs/Data_Files/alice_novel.txt\n",
    "\n",
    "# open the file and read it into a variable alice_novel\n",
    "alice_novel = open('alice_novel.txt', 'r').read()\n",
    "    \n",
    "print ('File downloaded and saved!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next, let's use the stopwords that we imported from `word_cloud`. We use the function *set* to remove any redundant stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = set(STOPWORDS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a word cloud object and generate a word cloud. For simplicity, let's generate a word cloud using only the first 2000 words in the novel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a word cloud object\n",
    "alice_wc = WordCloud(\n",
    "    background_color='white',\n",
    "    max_words=2000,\n",
    "    stopwords=stopwords\n",
    ")\n",
    "\n",
    "# generate the word cloud\n",
    "alice_wc.generate(alice_novel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the word cloud\n",
    "fig = plt.figure()\n",
    "fig.set_figwidth(14) # set width\n",
    "fig.set_figheight(18) # set height\n",
    "\n",
    "# display the cloud\n",
    "plt.imshow(alice_wc, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Much better! However, **said** isn't really an informative word. So let's add it to our stopwords and re-generate the cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords.add('said') # add the words said to stopwords\n",
    "\n",
    "# re-generate the word cloud\n",
    "alice_wc.generate(alice_novel)\n",
    "\n",
    "# display the cloud\n",
    "fig = plt.figure()\n",
    "fig.set_figwidth(14) # set width\n",
    "fig.set_figheight(18) # set height\n",
    "\n",
    "plt.imshow(alice_wc, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's use a mask of Alice and her rabbit. We already created the mask for you, so let's go ahead and download it and call it alice_mask.png."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download image\n",
    "!wget --quiet https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DV0101EN/labs/Images/alice_mask.png\n",
    "    \n",
    "# save mask to alice_mask\n",
    "alice_mask = np.array(Image.open('alice_mask.png'))\n",
    "    \n",
    "print('Image downloaded and saved!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's take a look at how the mask looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "fig.set_figwidth(14) # set width\n",
    "fig.set_figheight(18) # set height\n",
    "\n",
    "plt.imshow(alice_mask, cmap=plt.cm.gray, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shaping the word cloud according to the mask is straightforward using word_cloud package. For simplicity, we will continue using the first 2000 words in the novel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate a word cloud object\n",
    "alice_wc = WordCloud(background_color='white', max_words=2000, mask=alice_mask, stopwords=stopwords)\n",
    "\n",
    "# generate the word cloud\n",
    "alice_wc.generate(alice_novel)\n",
    "\n",
    "# display the word cloud\n",
    "fig = plt.figure()\n",
    "fig.set_figwidth(14) # set width\n",
    "fig.set_figheight(18) # set height\n",
    "\n",
    "plt.imshow(alice_wc, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### On the Canada Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_immigration = df_can['Total'].sum()\n",
    "total_immigration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "max_words = 90\n",
    "word_string = ''\n",
    "for country in df_can.index.values:\n",
    "    # check if country's name is a single-word name\n",
    "    if len(country.split(' ')) == 1:\n",
    "        repeat_num_times = int(df_can.loc[country, 'Total']/float(total_immigration)*max_words)\n",
    "        word_string = word_string + ((country + ' ') * repeat_num_times)\n",
    "                                     \n",
    "# display the generated text\n",
    "word_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the word cloud\n",
    "wordcloud = WordCloud(background_color='white').generate(word_string)\n",
    "\n",
    "print('Word cloud created!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the cloud\n",
    "fig = plt.figure()\n",
    "fig.set_figwidth(14)\n",
    "fig.set_figheight(18)\n",
    "\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Seaborn regression plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a new dataframe that stores that total number of landed immigrants to Canada per year from 1980 to 2013."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can use the sum() method to get the total population per year\n",
    "df_tot = pd.DataFrame(df_can[list(map(str, range(1980, 2014)))].sum(axis=0))\n",
    "\n",
    "# change the years to type float (useful for regression later on)\n",
    "df_tot.index = map(float, df_tot.index)\n",
    "\n",
    "# reset the index to put in back in as a column in the df_tot dataframe\n",
    "df_tot.reset_index(inplace=True)\n",
    "\n",
    "# rename columns\n",
    "df_tot.columns = ['year', 'total']\n",
    "\n",
    "# view the final dataframe\n",
    "df_tot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating a regression plot is as simple as calling the regplot function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "ax = sns.regplot(x='year', y='total', data=df_tot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's change the color to green"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "ax = sns.regplot(x='year', y='total', data=df_tot, color='green')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can always customize the marker shape, so instead of circular markers, let's use '+'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "ax = sns.regplot(x='year', y='total', data=df_tot, color='green', marker='+')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's blow up the plot a little bit so that it is more appealing to the sight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "ax = sns.regplot(x='year', y='total', data=df_tot, color='green', marker='+')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's increase the size of markers so they match the new size of the figure, and add a title and x- and y-labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "ax = sns.regplot(x='year', y='total', data=df_tot, color='green', marker='+', scatter_kws={'s': 200})\n",
    "\n",
    "ax.set(xlabel='Year', ylabel='Total Immigration') # add x- and y-labels\n",
    "ax.set_title('Total Immigration to Canada from 1980 - 2013') # add title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally increase the font size of the tickmark labels, the title, and the x- and y-labels so they don't feel left out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "\n",
    "ax = sns.regplot(x='year', y='total', data=df_tot, color='green', marker='+', scatter_kws={'s': 200})\n",
    "ax.set(xlabel='Year', ylabel='Total Immigration')\n",
    "ax.set_title('Total Immigration to Canada from 1980 - 2013')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the style to a white plain background."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "sns.set_style('ticks') # change background to white background\n",
    "\n",
    "ax = sns.regplot(x='year', y='total', data=df_tot, color='green', marker='+', scatter_kws={'s': 200})\n",
    "ax.set(xlabel='Year', ylabel='Total Immigration')\n",
    "ax.set_title('Total Immigration to Canada from 1980 - 2013')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or to a white background with gridlines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "sns.set(font_scale=1.5)\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "ax = sns.regplot(x='year', y='total', data=df_tot, color='green', marker='+', scatter_kws={'s': 200})\n",
    "ax.set(xlabel='Year', ylabel='Total Immigration')\n",
    "ax.set_title('Total Immigration to Canada from 1980 - 2013')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!conda install -c conda-forge folium=0.5.0 --yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "world_map = folium.Map(location=[56, -106], zoom_start=4)\n",
    "world_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression\n",
    "Two types of testing:\n",
    "- test on a potion of the train set (a.)\n",
    "- train/test split (b.)\n",
    "- k-fold cross validation (c.)\n",
    "# IMAG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation of the model (metrics):\n",
    "- MSE: mean squared error\n",
    "- RMSE: root mean squared error\n",
    "- RSE: sum(yi - 'yi)ˆ2 / sum(yi - mean(y))ˆ2\n",
    "- Rˆ2: 1 - RSE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
