{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Regression\n",
    "### The most popular regression algorithms are:\n",
    "1. Linear Regression\n",
    "2. Logistic Regression\n",
    "3. Ordinary Least Squares Regression (OLSR)\n",
    "4. Stepwise Regression\n",
    "5. Multivariate Adaptive Regression Splines (MARS)\n",
    "6. Locally Estimated Scatterplot Smoothing (LOESS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.1. Linear regression\n",
    "<img src=\"data/images/linear_regression.png\" alt=\"xxx\" title=\"title\" width=260 height=260 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is a form of predictive technique, used in trends, estimates, impact of price changes <br>\n",
    "$$y = mx + c$$\n",
    "- m = slope of the line\n",
    "- c = intercept of the line\n",
    "$$ m = \\frac{∑(x - x̄)(y - ӯ)}{∑(x - x̄)^2}$$\n",
    "The error (better when closer to 1)/Least squares/Residuals: <br>\n",
    "$$ R^2 = \\frac{∑(y_{pred} - ӯ)}{∑(y - ӯ)^2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.2. Logistic Regression\n",
    "\n",
    "<img src=\"data/images/logistic_regression.png\" alt=\"xxx\" title=\"title\" width=260 height=260 />\n",
    "\n",
    "Logistic regression provides probabilities. <br>\n",
    "Logistic regression produces results in a binary format: <br>\n",
    "- 0 or 1\n",
    "- Yes or No\n",
    "- True or False\n",
    "- High or Low"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression doesn't have the concept of residuals, so it can't use least squares. <br>\n",
    "Instead, it uses the maximum likelihood.\n",
    "<img src=\"data/images/logistic_regression_likelihood.png\" alt=\"xxx\" title=\"title\" width=460 height=460 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.3. Ordinary Least Squares Regression (OLSR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/images/OLSR.png\" alt=\"xxx\" title=\"title\" width=460 height=460 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "# 1.4. Stepwise Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Is a tool used to \"pool\" the features which doesn't have such a big impact for our prediction model\n",
    "- Stepwise attempts to find the most important variables\n",
    "- E.g.: The price of a house is impacted by number of rooms and location, but not by color."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How it works:\n",
    " - assume we have n independent variables\n",
    " - Step1: we create all possible n models: E(y) = B_0 + B_1 * x_k\n",
    "  - we choose the most signigicant xi\n",
    " - Step2: we create all possible n-1 models:E(y) = B_0 + B_1 * x_1 + B_2 * x_k\n",
    "  - we choose the most signigicant xi\n",
    " - We repeat the steps until the variable doesn't impact the model that much\n",
    "\n",
    "#### Methods to choose the best variable:\n",
    " - p value (smallest)\n",
    " - standard deviation\n",
    " - R squared\n",
    "\n",
    "#### Drawbacks:\n",
    "- Only linear terms are considered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.5. Multivariate Adaptive Regression Splines (MARS)\n",
    "\n",
    "- MARS models fits piecewise linear models\n",
    "- Hinge functions are used to \"cut\" the lines into sectors which could be easly shaped with linear functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/images/spline_regression.png\" alt=\"xxx\" title=\"title\" width=460 height=460 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/images/MARS.png\" alt=\"xxx\" title=\"title\" width=460 height=460 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"data/images/1vs2_cut_points.png\" alt=\"xxx\" title=\"title\" width=460 height=460 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.6. Locally Estimated Scatterplot Smoothing (LOESS)\n",
    "\n",
    "\n",
    "#### Steps:\n",
    "- The data to be fitted\n",
    "<img src=\"data/images/LOESS1.png\" alt=\"xxx\" title=\"title\" width=460 height=460 />\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Divide the data into smaller blobs: 5 points\n",
    "\n",
    "<img src=\"data/images/LOESS2.png\" alt=\"xxx\" title=\"title\" width=460 height=460 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Within this window, each point will be focal point.\n",
    "- The focal point has the biggest weight, the next points has smaller weight proportional with the distance\n",
    "<img src=\"data/images/LOESS3.png\" alt=\"xxx\" title=\"title\" width=460 height=460 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- After this, you'll have the fierst point of the fitted curve. It will be after that updated with respect of the distance between the curve and the actual point\n",
    "<img src=\"data/images/LOESS4.png\" alt=\"xxx\" title=\"title\" width=460 height=460 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here comes the 2nd weight\n",
    "<img src=\"data/images/LOESS5.png\" alt=\"xxx\" title=\"title\" width=460 height=460 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The curve after taking into consideration both weights (distance comparing to focal points and distance between the curve and the point)\n",
    "<img src=\"data/images/LOESS6.png\" alt=\"xxx\" title=\"title\" width=460 height=460 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Additional consideration:\n",
    "- Lines or parabolas\n",
    "<img src=\"data/images/LOESS7.png\" alt=\"xxx\" title=\"title\" width=460 height=460 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Difference between the two\n",
    "<img src=\"data/images/LOESS8.png\" alt=\"xxx\" title=\"title\" width=460 height=460 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The functions for the 2 weights:\n",
    "<img src=\"data/images/LOESS9.png\" alt=\"xxx\" title=\"title\" width=460 height=460 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Classification\n",
    "### The most popular instance-based algorithms are:\n",
    "1. k-Nearest Neighbor (kNN)\n",
    "2. Learning Vector Quantization (LVQ)\n",
    "3. Self-Organizing Map (SOM)\n",
    "4. Locally Weighted Learning (LWL)\n",
    "5. Support Vector Machines (SVM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 k-Nearest Neighbor (kNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Finds the nearest n neighbors, and it decides which class is the new element, seeing which neighbors has the most votes\n",
    "<img src=\"data/images/knn1.png\" alt=\"xxx\" title=\"title\" width=460 height=460 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When k=1, each training vector defines a region in space, defining a Voronoi partition of space\n",
    "<img src=\"data/images/knn2.png\" alt=\"xxx\" title=\"title\" width=460 height=460 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remarks:\n",
    "- For a two class problem, an odd k value must be chosen\n",
    "- k must not be a multiple of the number of classes\n",
    "- not so scalable (for large datasets, it can be a problem because many distances has to be calculated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.2 Learning vector quantization (lvq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Clustering\n",
    "### The most popular clustering algorithms are:\n",
    "1. k-Means\n",
    "2. k-Medians\n",
    "3. Expectation Maximisation (EM)\n",
    "4. Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. The most popular Bayesian algorithms are:\n",
    "1. Naive Bayes\n",
    "2. Gaussian Naive Bayes\n",
    "3. Multinomial Naive Bayes\n",
    "4. Averaged One-Dependence Estimators (AODE)\n",
    "5. Bayesian Belief Network (BBN)\n",
    "6. Bayesian Network (BN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Algorithms\n",
    "1. Decision Tree\n",
    "2. Random Forest\n",
    "3. Dimensionality Reduction Algorithms\n",
    "4. Gradient Boosting algorithms\n",
    "5. GBM\n",
    "6. XGBoost\n",
    "7. LightGBM\n",
    "8. CatBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
